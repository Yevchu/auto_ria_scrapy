The logic of the scraper: after activating the scraper, it extracts from the main link (https://auto.ria.com/car/used/) links to all the cars that are on the site, then these links are passed to the following function that goes through each received link and extracts the information we need: (url (string) title (string) price_usd (number) odometer (number, you need to convert 95 thousand. to 95000 and write it as a number) username (string) phone_number (number, example structure: +38063........) image_url (string) images_count (number) car_number (string) car_vin (string) datetime_found (date of saving to the database) ) After that, the information is cleaned and brought to a single standard and then written to the database.

To run the scraper, follow these steps: 1.install all the necessary packages using the command: pip install -r requirements.txt and rename the env file to .env 2.start docker-compose with the command: docker-compose up 3.go to the auto_ria_scrapy folder with the command: cd auto_ria_scrapy 4.start the scraper with the command python main.py 4.1 first, the database dump is activated to make a backup. in the terminal, enter the password: 567234 4.2 after a successful backup, the scraper will start and start extracting data from the author. the scraping process takes some time (you can stop the scraping process in advance with the key combination ctrl+c)
